{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KIE.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjih8UOwviqk"
      },
      "source": [
        "Tessaract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9qDmZTlvgY6",
        "outputId": "821cc1bb-1357-4ad6-e30c-e28e76462643"
      },
      "source": [
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 2s (2,720 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 145483 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 16 not upgraded.\n",
            "Need to get 2,755 kB of archives.\n",
            "After this operation, 13.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libleptonica-dev amd64 1.75.3-3 [1,308 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtesseract-dev amd64 4.00~git2288-10f4998a-2 [1,447 kB]\n",
            "Fetched 2,755 kB in 2s (1,633 kB/s)\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "(Reading database ... 145530 files and directories currently installed.)\n",
            "Preparing to unpack .../libleptonica-dev_1.75.3-3_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.75.3-3) ...\n",
            "Selecting previously unselected package libtesseract-dev.\n",
            "Preparing to unpack .../libtesseract-dev_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking libtesseract-dev (4.00~git2288-10f4998a-2) ...\n",
            "Setting up libleptonica-dev (1.75.3-3) ...\n",
            "Setting up libtesseract-dev (4.00~git2288-10f4998a-2) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZIxjXrohJLW"
      },
      "source": [
        "#Pytessaract"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhTuUSegv9Vl",
        "outputId": "15c21f86-56f9-4811-9a19-571b3d4c9bea"
      },
      "source": [
        "! pip install Pillow\n",
        "! pip install pytesseract"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/e6/a4e9fc8a93c1318540e8de6d8d4beb5749b7960388a7c7f27799fc2dd016/pytesseract-0.3.7.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from pytesseract) (7.0.0)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.7-py2.py3-none-any.whl size=13945 sha256=d637f0ef29f81a252b39541730cd56e7aafa39c83ee2f4bd5d32995a7e26a82a\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/20/7e/1dd0daad1575d5260916bb1e9781246430647adaef4b3ca3b3\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgoNgjhiwDkO"
      },
      "source": [
        "import pytesseract\n",
        "from PIL import ImageEnhance, ImageFilter, Image"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOWrMvAnxYmE"
      },
      "source": [
        "\n",
        "def get_acc(directory, path):\n",
        "#def get_acc(/content/out, /content/out/001.jpg ):\n",
        "    font     = cv2.FONT_HERSHEY_SIMPLEX\n",
        "    fontScale = 0.5\n",
        "    fontColor  = (255,0,0)\n",
        "    lineType = 1\n",
        "    path = directory+path\n",
        "    #path = \"/content/out/001.jpg\"\n",
        "    #path = '/content/000.jpg'\n",
        "    #path = args['/content/out/001.jpg']\n",
        "    #op_path = args['/content/sample_data']\n",
        "\n",
        "    op_path = directory\n",
        "    if op_path[-1]!='/':\n",
        "    \top_path.append('/')\n",
        "\n",
        "\n",
        "    #Threshold\n",
        "    image = cv2.imread(path)\n",
        "\n",
        "    height,width,channel = image.shape\n",
        "\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    T = threshold_local(gray, 15, offset = 6, method = \"gaussian\") # generic, mean, median, gaussian\n",
        "    thresh = (gray > T).astype(\"uint8\") * 255\n",
        "    thresh = ~thresh\n",
        "\n",
        "\n",
        "    #Dilation\n",
        "    kernel =np.ones((1,1), np.uint8)\n",
        "    ero = cv2.erode(thresh, kernel, iterations= 1)\n",
        "    img_dilation = cv2.dilate(ero, kernel, iterations=1)\n",
        "\n",
        "    # Remove noise\n",
        "    nlabels, labels, stats, centroids = cv2.connectedComponentsWithStats(img_dilation, None, None, None, 8, cv2.CV_32S)\n",
        "    sizes = stats[1:, -1] #get CC_STAT_AREA component\n",
        "    final = np.zeros((labels.shape), np.uint8)\n",
        "    for i in range(0, nlabels - 1):\n",
        "        if sizes[i] >= 10:   #filter small dotted regions\n",
        "            final[labels == i + 1] = 255\n",
        "\n",
        "    kern = np.ones((5,15), np.uint8)\n",
        "    img_dilation = cv2.dilate(final, kern, iterations = 1)\n",
        "    contours, hierarchy = cv2.findContours(img_dilation, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "    rects = map(lambda c: cv2.boundingRect(c), contours)\n",
        "    sorted_rects = sorted(rects, key =lambda r: r[0])\n",
        "    sorted_rects = sorted(sorted_rects, key =lambda r: r[1])\n",
        "\n",
        "    tt = image.copy()\n",
        "    dictionary = {}\n",
        "    etfo=''\n",
        "    for i,rect in enumerate(sorted_rects):\n",
        "        temp_dic = {}\n",
        "        x,y,w,h = rect\n",
        "        if(w<20 or h<20):\n",
        "            continue\n",
        "        temp_dic['coords'] = [x,y,w,h]\n",
        "        words = []\n",
        "        temp = tt[y:y+h, x:x+w]\n",
        "        temp = cv2.cvtColor(temp, cv2.COLOR_BGR2RGB)\n",
        "        hi = pytesseract.image_to_data(temp, config=r'--psm 6')\n",
        "        hi = hi.split()\n",
        "        ind = 22\n",
        "        while(True):\n",
        "            if (ind>len(hi)):\n",
        "                break\n",
        "            if(int(hi[ind])==-1):\n",
        "                ind+=11\n",
        "            else:\n",
        "\n",
        "                tem = {}\n",
        "                tem['confidence'] = hi[ind]\n",
        "                tem['text'] = hi[ind+1]\n",
        "                etfo=etfo+hi[ind+1]\n",
        "                etfo=etfo+\" \"\n",
        "                x+=len(hi[ind+1])*20\n",
        "                ind+=12\n",
        "                words.append(tem)\n",
        "        temp_dic['words'] = words\n",
        "        etfo=etfo+'\\n'\n",
        "        #cvw.rectangle(image, rect, cvw.Color.GREEN, thickness=1)\n",
        "        dictionary[i] = temp_dic\n",
        "\n",
        "\n",
        "    cv2.imwrite(op_path+\"result.jpg\", image)\n",
        "    return json.dumps(dictionary),etfo\n",
        "\n",
        "    #cv2_imshow(\"res\",image)\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "uvGMd7177CT2",
        "outputId": "2bae1d61-13cd-45a2-f6a2-614e9dcf91f1"
      },
      "source": [
        "import cv2\n",
        "import argparse\n",
        "import numpy as np\n",
        "!pip install opencv-wrapper\n",
        "import opencv_wrapper as cvw\n",
        "from skimage.filters import threshold_local\n",
        "import json"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting opencv-wrapper\n",
            "  Downloading https://files.pythonhosted.org/packages/a6/35/07177ec8074623831493c793643b6ec8c444fbc0d7f73a9dfdba486ce65a/opencv-wrapper-0.2.3.tar.gz\n",
            "Collecting numpy<=1.16.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/d5/4f8410ac303e690144f0a0603c4b8fd3b986feb2749c435f7cdbb288f17e/numpy-1.16.2-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 252kB/s \n",
            "\u001b[?25hCollecting opencv-python<=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/49/874d119948a5a084a7ebe98308214098ef3471d76ab74200f9800efeef15/opencv_python-4.0.0.21-cp36-cp36m-manylinux1_x86_64.whl (25.4MB)\n",
            "\u001b[K     |████████████████████████████████| 25.4MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from opencv-wrapper) (0.8)\n",
            "Building wheels for collected packages: opencv-wrapper\n",
            "  Building wheel for opencv-wrapper (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opencv-wrapper: filename=opencv_wrapper-0.2.3-py2.py3-none-any.whl size=18580 sha256=7efee24fa397be04b3c0665afe6ef2c6b9f6038ce2d90bad5c2eb60bef675d6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/74/fc/22/03106b3bcb2516e69317562a2aa4ceb94b0d5813a448edd928\n",
            "Successfully built opencv-wrapper\n",
            "\u001b[31mERROR: umap-learn 0.4.6 has requirement numpy>=1.17, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.0 has requirement numpy~=1.19.2, but you'll have numpy 1.16.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, opencv-python, opencv-wrapper\n",
            "  Found existing installation: numpy 1.19.4\n",
            "    Uninstalling numpy-1.19.4:\n",
            "      Successfully uninstalled numpy-1.19.4\n",
            "  Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "Successfully installed numpy-1.16.2 opencv-python-4.0.0.21 opencv-wrapper-0.2.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSoii-G46BNO",
        "outputId": "07800f8a-7c0b-4321-9532-c7621f85569c"
      },
      "source": [
        "#Provide path of test image present in the created folder at “gson_data,etfo”\n",
        "\n",
        "gson_data, etfo = get_acc('/content/out/','000.jpg')\n",
        "print(gson_data)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"1\": {\"coords\": [68, 30, 258, 35], \"words\": [{\"confidence\": \"93\", \"text\": \"tan\"}, {\"confidence\": \"89\", \"text\": \"woon\"}, {\"confidence\": \"91\", \"text\": \"yann\"}]}, \"3\": {\"coords\": [66, 93, 361, 22], \"words\": [{\"confidence\": \"93\", \"text\": \"BOOK\"}, {\"confidence\": \"83\", \"text\": \"TA_K\"}, {\"confidence\": \"90\", \"text\": \"(TAMAN\"}, {\"confidence\": \"91\", \"text\": \"DAYA)\"}, {\"confidence\": \"90\", \"text\": \"SDN\"}, {\"confidence\": \"47\", \"text\": \"BHD\"}]}, \"5\": {\"coords\": [158, 142, 231, 24], \"words\": [{\"confidence\": \"7\", \"text\": \"$5.57\"}, {\"confidence\": \"92\", \"text\": \"&\"}, {\"confidence\": \"83\", \"text\": \"58,\"}, {\"confidence\": \"92\", \"text\": \"JALAN\"}, {\"confidence\": \"88\", \"text\": \"SAGU\"}, {\"confidence\": \"80\", \"text\": \"18,\"}]}, \"8\": {\"coords\": [185, 167, 121, 23], \"words\": [{\"confidence\": \"88\", \"text\": \"TAMAN\"}, {\"confidence\": \"63\", \"text\": \"DAYA\"}]}, \"10\": {\"coords\": [157, 191, 184, 22], \"words\": [{\"confidence\": \"86\", \"text\": \"81100\"}, {\"confidence\": \"92\", \"text\": \"JOHOR\"}, {\"confidence\": \"35\", \"text\": \"BAHRU.\"}]}, \"12\": {\"coords\": [86, 271, 319, 53], \"words\": [{\"confidence\": \"16\", \"text\": \"db\"}, {\"confidence\": \"0\", \"text\": \"STEHT\"}]}, \"15\": {\"coords\": [158, 371, 191, 21], \"words\": [{\"confidence\": \"93\", \"text\": \"25/12/2018\"}, {\"confidence\": \"65\", \"text\": \"8:13:39\"}, {\"confidence\": \"70\", \"text\": \"PM\"}]}, \"20\": {\"coords\": [186, 458, 119, 21], \"words\": [{\"confidence\": \"95\", \"text\": \"CASH\"}, {\"confidence\": \"95\", \"text\": \"BILL\"}]}, \"28\": {\"coords\": [24, 506, 105, 21], \"words\": [{\"confidence\": \"70\", \"text\": \"CODE/DESC\"}]}, \"31\": {\"coords\": [64, 530, 46, 22], \"words\": [{\"confidence\": \"35\", \"text\": \"Qry\"}]}, \"58\": {\"coords\": [113, 668, 178, 22], \"words\": [{\"confidence\": \"92\", \"text\": \"Rour\"}, {\"confidence\": \"92\", \"text\": \"ding\"}, {\"confidence\": \"96\", \"text\": \"Adjustment\"}]}, \"65\": {\"coords\": [81, 701, 218, 25], \"words\": [{\"confidence\": \"69\", \"text\": \"Round:\"}, {\"confidence\": \"57\", \"text\": \":d\"}, {\"confidence\": \"94\", \"text\": \"Total\"}, {\"confidence\": \"93\", \"text\": \"(RM);\"}]}, \"67\": {\"coords\": [91, 732, 362, 128], \"words\": [{\"confidence\": \"95\", \"text\": \"Cash\"}, {\"confidence\": \"56\", \"text\": \"9\"}, {\"confidence\": \"9\", \"text\": \"'\"}, {\"confidence\": \"84\", \"text\": \"40.00\"}, {\"confidence\": \"96\", \"text\": \"CHANGE\"}, {\"confidence\": \"57\", \"text\": \"00:\"}, {\"confidence\": \"43\", \"text\": \"Do\"}, {\"confidence\": \"63\", \"text\": \"0\"}, {\"confidence\": \"89\", \"text\": \"GOODS\"}, {\"confidence\": \"84\", \"text\": \"SOLD\"}, {\"confidence\": \"73\", \"text\": \"ARE\"}, {\"confidence\": \"92\", \"text\": \"NOT\"}, {\"confidence\": \"40\", \"text\": \"RETURINAT\"}, {\"confidence\": \"33\", \"text\": \"aK\"}]}, \"71\": {\"coords\": [319, 744, 96, 101], \"words\": [{\"confidence\": \"39\", \"text\": \"\\\"Wap,\"}, {\"confidence\": \"29\", \"text\": \"00,\"}]}, \"74\": {\"coords\": [331, 778, 74, 46], \"words\": [{\"confidence\": \"71\", \"text\": \"?-00\"}]}, \"78\": {\"coords\": [131, 881, 229, 41], \"words\": [{\"confidence\": \"6\", \"text\": \"HOPE,\"}, {\"confidence\": \"0\", \"text\": \"f,\"}, {\"confidence\": \"0\", \"text\": \"ROB\"}, {\"confidence\": \"48\", \"text\": \"ate\"}, {\"confidence\": \"21\", \"text\": \"ls\"}, {\"confidence\": \"58\", \"text\": \"oo\"}, {\"confidence\": \"57\", \"text\": \"fa\"}, {\"confidence\": \"57\", \"text\": \"7\"}, {\"confidence\": \"34\", \"text\": \"0,\"}, {\"confidence\": \"0\", \"text\": \"GOae\"}, {\"confidence\": \"26\", \"text\": \"yet.\"}, {\"confidence\": \"0\", \"text\": \"ata!\"}]}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDQ3U2Y-7L-I"
      },
      "source": [
        "import argparse\n",
        "import torch\n",
        "import json\n",
        "from torch import nn"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJWr4DIE7jaf"
      },
      "source": [
        "class MyModel0(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers=2, bidirectional=True)\n",
        "        self.linear = nn.Linear(hidden_size * 2, 5)\n",
        "\n",
        "    def forward(self, inpt):\n",
        "        embedded = self.embed(inpt)\n",
        "        feature, _ = self.lstm(embedded)\n",
        "        oupt = self.linear(feature)\n",
        "        return oupt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vWtLo8y7lef",
        "outputId": "6d9103ed-3adf-44b8-9564-97440a48f3f4"
      },
      "source": [
        "#Installing Colorama.\n",
        "!pip install colorama"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guxsxi1Y7ujP"
      },
      "source": [
        "import json\n",
        "import os\n",
        "import random\n",
        "from os import path\n",
        "from string import ascii_uppercase, digits, punctuation\n",
        "\n",
        "import colorama\n",
        "import numpy\n",
        "import regex"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjsFyyUe7yfj"
      },
      "source": [
        "\n",
        "VOCAB= ascii_uppercase+digits+punctuation+\" \\t\\n\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYsFeCDb72DI",
        "outputId": "a799d22c-c89b-4ae6-b0ea-42f43422f20a"
      },
      "source": [
        "print(etfo)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tan woon yann \n",
            "BOOK TA_K (TAMAN DAYA) SDN BHD \n",
            "$5.57 & 58, JALAN SAGU 18, \n",
            "TAMAN DAYA \n",
            "81100 JOHOR BAHRU. \n",
            "db STEHT \n",
            "25/12/2018 8:13:39 PM \n",
            "CASH BILL \n",
            "CODE/DESC \n",
            "Qry \n",
            "Rour ding Adjustment \n",
            "Round: :d Total (RM); \n",
            "Cash 9 ' 40.00 CHANGE 00: Do 0 GOODS SOLD ARE NOT RETURINAT aK \n",
            "\"Wap, 00, \n",
            "?-00 \n",
            "HOPE, f, ROB ate ls oo fa 7 0, GOae yet. ata! \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCAYSrw99tGe"
      },
      "source": [
        "#Creating text_tensor using pytorch\n",
        "\n",
        "device= 'cpu'\n",
        "hidden_size = 256\n",
        "\n",
        "device= torch.device('cpu')\n",
        "def get_test_data():\n",
        "    \n",
        "    text = etfo\n",
        "    text_tensor = torch.zeros(len(text), 1, dtype=torch.long)\n",
        "    text_tensor[:, 0] = torch.LongTensor([VOCAB.find(c) for c in text])\n",
        "\n",
        "    return text_tensor.to(device)\n",
        "\n",
        "text_tensor = get_test_data()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3t8veGK-Ghe",
        "outputId": "b7627ae0-f423-47ed-be7f-27951c9bedb6"
      },
      "source": [
        "\n",
        "print(text_tensor.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([340, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFi8ccvB-PIr"
      },
      "source": [
        "def pred_to_dict(text, pred, prob):\n",
        "    res = {\"company\": (\"\", 0), \"date\": (\"\", 0), \"address\": (\"\", 0), \"total\": (\"\", 0)}\n",
        "    keys = list(res.keys())\n",
        "\n",
        "    seps = [0] + (numpy.nonzero(numpy.diff(pred))[0] + 1).tolist() + [len(pred)]\n",
        "    for i in range(len(seps) - 1):\n",
        "        pred_class = pred[seps[i]] - 1\n",
        "        if pred_class == -1:\n",
        "            continue\n",
        "\n",
        "        new_key = keys[pred_class]\n",
        "        new_prob = prob[seps[i] : seps[i + 1]].max()\n",
        "        if new_prob > res[new_key][1]:\n",
        "            res[new_key] = (text[seps[i] : seps[i + 1]], new_prob)\n",
        "\n",
        "    return {k: regex.sub(r\"[\\t\\n]\", \" \", v[0].strip()) for k, v in res.items()}\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5FLPayV-dpi",
        "outputId": "9eda605d-bff7-420d-f286-cd13b52a5bda"
      },
      "source": [
        "#Check for the less error-free size of \"torch.size\" \n",
        "#for this time i had to check for 5 times\n",
        "\n",
        "print(text_tensor.shape)\n",
        "for i in range(len(text_tensor)-1):\n",
        "  if text_tensor[i]<0 or text_tensor[i]>70:\n",
        "    text_tensor = torch.cat([text_tensor[0:i], text_tensor[i+1:]])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([276, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkrDLyfhhSHz"
      },
      "source": [
        "#Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VkSc3TDAB15",
        "outputId": "df3b1d65-e006-4ce3-90c6-5ff7a64ed768"
      },
      "source": [
        "#Making use of trained model “model.pth” from Zhang for testing on images.\n",
        "\n",
        "def test():\n",
        "    \n",
        "    model = MyModel0(len(VOCAB), 16, hidden_size).to(device)\n",
        "  \n",
        "\n",
        "    model.load_state_dict(torch.load(\"/content/out/model.pth\"))\n",
        "\n",
        "    model.eval()\n",
        "  \n",
        "    with torch.no_grad():\n",
        "            oupt = model(text_tensor)\n",
        "            prob = torch.nn.functional.softmax(oupt, dim=2)\n",
        "            prob, pred = torch.max(prob, dim=2)\n",
        "            prob = prob.squeeze().cpu().numpy()\n",
        "            pred = pred.squeeze().cpu().numpy()\n",
        "            real_text = etfo\n",
        "            result = pred_to_dict(real_text, pred, prob)\n",
        "\n",
        "            with open(\"/content/out/result\" + 'result' + \".json\", \"w\", encoding=\"utf-8\") as json_opened:\n",
        "                json.dump(result, json_opened, indent=4)\n",
        "\n",
        "            print(result)\n",
        "            #print(key)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'company': 'woon yann  BOOK TA_K (TAMAN DAY', 'date': '.  db STEH', 'address': 'DN BHD  $5.57 & 58, JALAN SAGU 18,  TAMAN DAYA  81100 JOHOR BAHR', 'total': ''}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}